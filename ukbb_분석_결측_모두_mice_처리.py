# -*- coding: utf-8 -*-
"""UKBB 분석-결측 모두 MICE 처리.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11x3tjCXCV7CXS8Jd2uN8jqHNQVruqLMT
"""

import pandas as pd
import numpy as np

# 1. 파일 경로 설정
file_path = r"C:\Users\KOREA Univ\OneDrive\기타\바탕 화면\workplace\3. 학위논문\backpain_28639사용.phe_participant.csv"

data = pd.read_csv(file_path)
data.columns = data.columns.str.strip()  # 열 이름 공백 제거

data.info()

# Column 명 변경
column_rename = {
   'eid': 'participant_id',
    'p28639': 'low_back_pain',
    'p31': 'sex',
    'p34': 'birth_year',
    'p21000_i0': 'ethnicity',
    'p6138_i0': 'education',
    'p738_i0': 'income',
    'p29169': 'occupation',
    'p29167': 'social_activity',
    'p29163': 'social_contacts_frequency',
    'p29162': 'household_size',
    'p30477': 'moderate_exercise_frequency',
    'p29091': 'alcohol_frequency',
    'p30445': 'sleep_hours',
    'p30575': 'fatigue_frequency',
    'p28738': 'feeling_depressed',
    'p28735': 'feeling_anxious',
}

data.rename(columns=column_rename, inplace=True)
print(">> Updated column names:")
print(data.columns.tolist())

data.info()

# 변수별 고유값과 각 값의 빈도수 출력
for col in data.columns:
    print(f"\n>>> [ {col} ] 값 분포:")
    print(data[col].value_counts(dropna=False))

"""## **object -> int로 변경**"""

# clean_and_map 함수 정의
def clean_and_map(column, mapping):
    data[column] = data[column].astype(str).str.strip().str.lower()
    data[column] = data[column].replace(mapping)
    data[column] = pd.to_numeric(data[column], errors="coerce").astype("Int64")

# sex
clean_and_map("sex", {
    "male": 0,
    "female": 1
})

print(">>> [ sex ] 값 분포:")
print(data["sex"].value_counts(dropna=False))

# low_back_pain
clean_and_map("low_back_pain", {
    "no": 0,
    "yes": 1,
    "do not know": np.nan,
    "prefer not to answer": np.nan
})

print(">>> [ low_back_pain ] 값 분포:")
print(data["low_back_pain"].value_counts(dropna=False))

# birth_year -> 2023년 기준 나이 계산 -> age 변수 삽입
data["age"] = 2023 - data["birth_year"].astype("Int64")

print(">>> [ age ] 값 분포:")
print(data["age"].value_counts().sort_index())

# ethnicity
clean_and_map("ethnicity", {
    "british": 0,
    "any other white background": 0,
    "irish": 0,
    "indian": 1,
    "any other asian background": 2,
    "asian or asian british": 2,
    "pakistani": 1,
    "bangladeshi": 1,
    "chinese": 3,
    "caribbean": 4,
    "african": 4,
    "black or black british": 4,
    "any other black background": 4,
    "white": 0,
    "mixed": 5,
    "white and asian": 5,
    "white and black caribbean": 5,
    "white and black african": 5,
    "any other mixed background": 5,
    "other ethnic group": 6,
    "prefer not to answer": np.nan,
    "do not know": np.nan
})

data["ethnicity"] = pd.to_numeric(data["ethnicity"], errors="coerce").astype("Int64")

print(">>> [ ethnicity ] 값 분포 (after mapping):")
print(data["ethnicity"].value_counts(dropna=False))

print(">>> [ occupation ] 값 분포:")
print(data["occupation"].value_counts(dropna=False))

# occupation
def map_occupation(val):
    if pd.isna(val):
        return np.nan
    val = val.lower().strip()
    if "self-employed" in val:
        return 2
    elif "employed" in val:
        return 1
    else:
        return 0

# 적용
data["occupation"] = data["occupation"].apply(map_occupation).astype("Int64")

# 결과 확인
print(">>> [ occupation ] 값 분포 (after mapping):")
print(data["occupation"].value_counts(dropna=False))

print(">>> [ education ] 값 분포:")
print(data["education"].value_counts(dropna=False))

# education
def map_education(val):
    if pd.isna(val):
        return np.nan
    val = val.lower().strip()

    if "prefer not to answer" in val:
        return np.nan
    elif "college or university degree" in val:
        return 4
    elif "nvq or hnd or hnc or equivalent" in val:
        return 3
    elif "a levels/as levels or equivalent" in val:
        return 2
    elif "o levels/gcses or equivalent" in val or "cse" in val:
        return 1
    elif "none of the above" in val:
        return 0
    else:
        return np.nan

# 적용
data["education"] = data["education"].apply(map_education).astype("Int64")

# 결과 확인
print(">>> [ education ] 값 분포 (after mapping):")
print(data["education"].value_counts(dropna=False))

# income
clean_and_map("income", {
    "less than 18,000": 0,
    "18,000 to 30,999": 1,
    "31,000 to 51,999": 2,
    "52,000 to 100,000": 3,
    "greater than 100,000": 4,
    "prefer not to answer": np.nan,
    "do not know": np.nan
})

# 정수형 변환
data["income"] = pd.to_numeric(data["income"], errors="coerce").astype("Int64")

# 결과 확인
print(">>> [ income ] 값 분포 (after mapping):")
print(data["income"].value_counts(dropna=False))

# social_activity
def map_social_activity(value):
    if pd.isna(value):
        return np.nan
    value = value.strip().lower()
    if "none of the above" in value:
        return 0
    if "prefer not to answer" in value:
        return np.nan
    return 1

data["social_activity"] = data["social_activity"].apply(map_social_activity).astype("Int64")

print(">>> [ social_activity ] 값 분포 (after mapping):")
print(data["social_activity"].value_counts(dropna=False))

# social_contacts_frequency
clean_and_map("social_contacts_frequency", {
    "never or almost never": 0,
    "once every few months": 1,
    "about once a month": 2,
    "about once a week": 3,
    "2-4 times a week": 4,
    "daily or almost daily": 5,
    "prefer not to answer": np.nan
})


data["social_contacts_frequency"] = (
    pd.to_numeric(data["social_contacts_frequency"], errors="coerce")
    .astype("Int64")
)

# 결과 확인
print(">>> [ social_contacts_frequency ] 값 분포 (after mapping):")
print(data["social_contacts_frequency"].value_counts(dropna=False))

# household_size
clean_and_map("household_size", {
    "only me": 0,
    "me and one other": 1,
    "more than two but less than five": 2,
    "five or more": 3,
    "prefer not to answer": np.nan
})

# 정수형으로 변환
data["household_size"] = (
    pd.to_numeric(data["household_size"], errors="coerce")
    .astype("Int64")
)

# 결과 확인
print(">>> [ household_size ] 값 분포 (after mapping):")
print(data["household_size"].value_counts(dropna=False))

# moderate_exercise_frequency
clean_and_map("moderate_exercise_frequency", {
    "daily": 4,
    "more than once a week": 3,
    "3-4 times": 2,
    "1-2 times": 1,
    "not at all": 0,
    "unable to exercise": 0,
    "prefer not to answer": np.nan
})

# 정수형으로 변환
data["moderate_exercise_frequency"] = (
    pd.to_numeric(data["moderate_exercise_frequency"], errors="coerce")
    .astype("Int64")
)

# 결과 확인
print(">>> [ moderate_exercise_frequency ] 값 분포 (after mapping):")
print(data["moderate_exercise_frequency"].value_counts(dropna=False))

# alcohol_frequency
clean_and_map("alcohol_frequency", {
    "never": 0,
    "monthly or less": 1,
    "2 to 4 times a month": 2,
    "2 to 3 times a week": 3,
    "4 or more times a week": 4,
    "prefer not to answer": np.nan
})

# 정수형으로 변환
data["alcohol_frequency"] = (
    pd.to_numeric(data["alcohol_frequency"], errors="coerce")
    .astype("Int64")
)

# 결과 확인
print(">>> [ alcohol_frequency ] 값 분포 (after mapping):")
print(data["alcohol_frequency"].value_counts(dropna=False))

# fatigue_frequency
clean_and_map("fatigue_frequency", {
    "0 days per week": 0,
    "1-2 days per week": 1,
    "3-4 days per week": 2,
    "5-6 days per week": 3,
    "7 days per week": 4
})

# 정수형으로 변환 (결측치 유지)
data["fatigue_frequency"] = pd.to_numeric(data["fatigue_frequency"], errors="coerce").astype("Int64")

# 결과 확인
print(">>> [ fatigue_frequency ] 값 분포 (after mapping):")
print(data["fatigue_frequency"].value_counts(dropna=False))

# feeling_depressed
clean_and_map("feeling_depressed", {
    "not at all": 0,
    "several days": 1,
    "more than half the days": 2,
    "nearly every day": 3,
    "prefer not to answer": np.nan
})

# 정수형으로 변환 (결측값 유지)
data["feeling_depressed"] = pd.to_numeric(data["feeling_depressed"], errors="coerce").astype("Int64")

# 결과 확인
print(">>> [ feeling_depressed ] 값 분포 (after mapping):")
print(data["feeling_depressed"].value_counts(dropna=False))

# feeling_anxious
clean_and_map("feeling_anxious", {
    "not at all": 0,
    "several days": 1,
    "more than half the days": 2,
    "nearly every day": 3,
    "prefer not to answer": np.nan
})

# 정수형으로 변환 (결측치 유지)
data["feeling_anxious"] = pd.to_numeric(data["feeling_anxious"], errors="coerce").astype("Int64")

# 결과 확인
print(">>> [ feeling_anxious ] 값 분포 (after mapping):")
print(data["feeling_anxious"].value_counts(dropna=False))

# sleep_hours : 현재 '분'(문자열)로 되어 있음 -> '시간'(정수형)으로 변환
data["sleep_hours"] = pd.to_numeric(data["sleep_hours"], errors="coerce")
data.loc[(data["sleep_hours"] < 60) | (data["sleep_hours"] > 960), "sleep_hours"] = np.nan #이상한 값 처리
data["sleep_hours"] = np.ceil(data["sleep_hours"] / 60).astype("Int64")

print(">>> [ sleep_hours ] 값 분포 (after ceil to integer hours):")
print(data["sleep_hours"].value_counts(dropna=False).sort_index())
print("\nData type:", data["sleep_hours"].dtype)

# 현재 코드 결 유지해서 다른 데이터 파일로 저장
# 저장 경로와 파일 이름 설정
save_path = r"C:\Users\KOREA Univ\OneDrive\기타\바탕 화면\workplace\3. 학위논문\backpain_28639사용.phe_participant_숫자변환.csv"
data.to_csv(save_path, index=False)

data.info()

data.drop(columns="birth_year", inplace=True) # birth_year 변수 제거
print(data.info())

# 현재 코드 결 유지해서 다른 데이터 파일로 저장_birth_year 제외
save_path = r"C:\Users\KOREA Univ\OneDrive\기타\바탕 화면\workplace\3. 학위논문\backpain_28639사용.phe_participant_숫자변환_birth제거.csv"
data.to_csv(save_path, index=False)

print(">>> [ low_back_pain ] 값 분포:")
print(data["low_back_pain"].value_counts(dropna=False))

# low_back_pain에서 결측값을 가진 행(row) 을 제거 >>> 372명 제거
data = data[data["low_back_pain"].notna()]
print(f"남은 행 개수: {len(data)}")
print(data["low_back_pain"].value_counts(dropna=False))

print(data.info())

"""## **MICE 통해 결측치 대체**      
> 범주형변수: 결측 모두 제거
> 연속형변수: sleep_hours, age만 MICE 대체
"""

print("\n>>> Missing values per column:")
print(data.isnull().sum())

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
import numpy as np

# MICE 대상 변수 (participant_id 제외)
target_columns = data.columns.drop(['participant_id'])

# 1. MICE 대체
imputer = IterativeImputer(max_iter=20, random_state=0)
imputed_data = imputer.fit_transform(data[target_columns])

# 2. 데이터프레임 재구성
imputed_df = pd.DataFrame(imputed_data, columns=target_columns)

# 3. 범주형 변수 정수 변환 (반올림)
categorical_columns = target_columns.drop(['sleep_hours', 'age'])
imputed_df[categorical_columns] = np.round(imputed_df[categorical_columns]).astype(int)

# 4. sleep_hours 소수 2자리로 유지
imputed_df['sleep_hours'] = imputed_df['sleep_hours'].round(2)

# 5. participant_id 병합
imputed_df['participant_id'] = data['participant_id'].values

imputed_df.info()

save_path = r"C:\Users\KOREA Univ\OneDrive\기타\바탕 화면\workplace\3. 학위논문\backpain_28639사용_결측처리(모두MICE).csv"
imputed_df.to_csv(save_path, index=False)

infor.data()



